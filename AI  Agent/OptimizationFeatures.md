# Функції оптимізації AI Unity Agent

AI Unity Agent тепер включає кілька функцій для оптимізації роботи та економії API токенів.

## 1. Кешування запитів

Кешування запитів дозволяє значно зменшити кількість звернень до API, що економить ваші токени та прискорює роботу з агентом.

### Як це працює:
- При першому запиті результат зберігається в локальному кеші
- При повторному запиті відповідь береться з кешу без звернення до API
- Кеш автоматично очищається від застарілих записів 

### Налаштування:
- **enableRequestCaching** - вмикає/вимикає кешування
- **cacheExpirationHours** - час (у годинах) до застарівання запису в кеші
- **Автоматичне очищення** - старі записи видаляються, якщо кеш переповнений

### Переваги:
- Економія токенів OpenAI/Gemini/Claude
- Миттєва відповідь на повторювані запитання
- Працює навіть при відсутності інтернету, якщо відповідь є в кеші

## 2. Автоматичне перепідключення

Система автоматичного перепідключення (RetryHelper) підвищує стійкість агента до проблем з мережею та тимчасових збоїв API.

### Як це працює:
- При виникненні мережевої помилки запит автоматично повторюється
- Налаштовувана кількість повторних спроб та затримка між ними
- Підтримує всі сервіси: OpenAI, Gemini, Claude, Ollama

### Налаштування:
- **useAutoRetry** - вмикає/вимикає автоматичне перепідключення
- Кількість повторних спроб за замовчуванням: 3
- Затримка між спробами: 1.5 секунди

### Переваги:
- Підвищена стійкість до проблем з мережею
- Зменшення кількості помилок для користувача
- Безшовна робота з нестабільним інтернет-підключенням

## 3. Інтеграція локальних моделей через Ollama

Ollama дозволяє використовувати потужні AI моделі локально, без API ключів та обмежень.

### Налаштування:
1. Встановіть [Ollama](https://ollama.ai/) на ваш комп'ютер
2. Запустіть Ollama
3. Встановіть бажану модель: `ollama pull llama3`
4. Налаштуйте AI Unity Agent для використання Ollama

### Доступні моделі:
- **llama3** - універсальна модель від Meta
- **codellama** - спеціалізована модель для генерації коду
- **mistral** - легка модель для слабших комп'ютерів
- **phi3** - компактна та ефективна модель від Microsoft

### Переваги:
- Повна приватність - дані не відправляються в інтернет
- Відсутність обмежень на кількість запитів
- Робота без інтернету
- Безкоштовне використання

## 4. Діагностичні інструменти

У нових версіях додано діагностичні інструменти для відлагодження та моніторингу продуктивності:

- **Статистика кешу** - кількість збережених запитів та розмір кешу
- **Час відповіді API** - вимірювання швидкості відповіді різних моделей
- **Індикатор джерела відповіді** - показує, чи взята відповідь з кешу, чи з API

## 5. Поради щодо оптимізації використання

- **Використовуйте кешування** для повторюваних запитів
- **Вибирайте модель залежно від задачі**:
  - Для генерації коду: CodeLlama через Ollama або Gemini Pro
  - Для швидкої допомоги: Claude-3-haiku або Gemini-1.5-flash
  - Для роботи без інтернету: будь-яка модель через Ollama
- **Економте токени**, обмежуючи розмір історії розмови
- **Вказуйте конкретні питання** замість загальних для кращого кешування
